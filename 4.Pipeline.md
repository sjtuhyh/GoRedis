
# Redis Pipeline
实际上Redis管道 (Pipeline) 本身并不是Redis服务器直接提供的技术，这个技术本质上是由客户端提供的
![image](https://user-images.githubusercontent.com/34932312/69850271-e34dd500-12b9-11ea-89a9-e47f3335d375.png)
服务器没有任何区别对待，收到一条消息执行一条消息，回复一条消息的正常的流程。
客户端通过对管道中的指令列表改变读写顺序就可以大幅节省IO时间。管道中指令越多，效果越好。

## 管道压力测试
Redis自带了一个压力测试工具 redis-benchmark，使用这个工具就可以进行管道测试。
```
> redis-benchmark -t set -q
SET: 51975.05 requests per second
```

我们加入管道选项-P参数，它表示单个管道内并行的请求数量，看下面P=2，QPS达到了9w/s。
```
> redis-benchmark -t set -P 2 -q 
SET: 91240.88 requests per second
```

但如果再继续提升P参数，发现 QPS已经上不去了，因为这里CPU处理能力已经达到了瓶颈，Redis的单线程CPU已经飙到了100%，所以无法再继续提升了。

## 深入理解管道本质
完整的请求交互流程图
![image](https://user-images.githubusercontent.com/34932312/69851134-e649c500-12bb-11ea-86b2-29888de74143.png)

- 客户端进程调用write将消息写到操作系统内核为套接字分配的发送缓冲send buffer
- 客户端操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过「网际路由」送到服务器的网卡
- 服务器操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲 recv buffer
- 服务器进程调用 read 从接收缓冲中取出消息进行处理
- 服务器进程调用 write 将响应消息写到内核为套接字分配的发送缓冲 send buffer
- 服务器操作系统内核将发送缓冲的内容发送到网卡，网卡硬件将数据通过「网际路由」送到客户端的网卡
- 客户端操作系统内核将网卡的数据放到内核为套接字分配的接收缓冲 recv buffer
- 客户端进程调用 read 从接收缓冲中取出消息返回给上层业务逻辑进行处理
- 结束

步骤 5~8 和 1~4 是一样的，只不过方向是反过来的，一个是请求，一个是响应。

我们开始以为 write 操作是要等到对方收到消息才会返回，但实际上不是这样的。write 操作只负责将数据写到本地操作系统内核的发送缓冲然后就返回了。剩下的事交给操作系统 内核异步将数据送到目标机器。但是如果发送缓冲满了，那么就需要等待缓冲空出空闲空间 来，这个就是写操作 IO 操作的真正耗时。

我们开始以为 read 操作是从目标机器拉取数据，但实际上不是这样的。read 操作只负 责将数据从本地操作系统内核的接收缓冲中取出来就了事了。但是如果缓冲是空的，那么就 需要等待数据到来，这个就是读操作 IO 操作的真正耗时。

所以对于 value = redis.get(key)这样一个简单的请求来说，write 操作几乎没有耗时，直接写到发送缓冲就返回，而 read 就会比较耗时了，因为它要等待消息经过网络路由到目标机器 处理后的响应消息,再回送到当前的内核读缓冲才可以返回。这才是一个网络来回的真正开 销。

而对于管道来说，连续的 write 操作根本就没有耗时，之后第一个 read 操作会等待一个 网络的来回开销，然后所有的响应消息就都已经回送到内核的读缓冲了，后续的 read 操作 直接就可以从缓冲拿到结果，瞬间就返回了。

