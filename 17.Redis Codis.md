# Redis Codis

在大数据高并发场景下，单个Redis实例往往会显得捉襟见肘。首先体现在内存上，单个Redis的内存不宜过大，`内存太大会导致rdb文件过大`，进一步导致主从同步时全量同步时间过长，在实例重启恢复时也会消耗很长的数据加载时间，特别是在云环境下，单个实例内存往往都是受限的。其次体现在CPU的利用率上，单个Redis实例只能利用单个核心，这单个核心要完成海量数据的存取和管理工作压力会非常大。

正是在这样的大数据高并发的需求之下，Redis 集群方案应运而生。它可以将众多小内存的Redis实例综合起来，`将分布在多台机器上的众多CPU核心的计算能力聚集到一起`，完成海量数据存储和高并发读写操作。

## Codis 介绍
Codis 是一种 Redis 集群的实现方案，与 Redis 社区的 Redis cluster 类似，基于 slot 的分片机制构建一个更大的 Redis 节点集群，对于连接到 codis 的 Redis 客户端来说, 除了部分不支持的命令外，与连接开源的 Redis Server 没有明显的区别, 客户端代码基本需要进行修改，Codis-proxy 会根据访问的 key 进行 slot 的计算，然后转发请求到对应的 Redis-server，对于客户端来说，中间的 codis-proxy 是不可见的，因此根据客户业务的需要，可以使用 codis 构建大规模的 Redis 服务，或者仅仅是用于把请求分担多个 Redis-server 提高系统的吞吐量。

![image](https://user-images.githubusercontent.com/34932312/71149408-646d0c00-2269-11ea-803c-dafbe3b7722a.png)

它的架构如上图所示，由codis-proxy对外提供Redis的服务。ZooKeeper用来存储数据路由表和codis-proxy节点的元信息。codis-proxy会监听所有的redis集群，当Redis集群处理能力达到上限时，可以动态增加Redis实例来实现扩容的需求。

### 组件介绍
- Codis Proxy: 对外提供Redis服务，除了一些不支持的命令外，表现的和原生的Redis没有区别。由于它是无状态的，所以我们可以部署多个节点，从而保证了可用性。
- Codis Dashboard: 集群管理工具，支持Codis Proxy的添加删除以及数据迁移等操作。对于一个Codis集群，Dashboard最多部署一个
- Codis Admin：集群管理的命令行工具
- Codis FE：集群管理界面，多个Codis集群可以共用一个Codis FE，通过配置文件管理后端的codis-dashboard
- Storage：为集群提供外部存储，目前支持ZooKeeper、Etcd、Fs三种。
- Codis Server：基于3.2.8分支开发，增加额外的数据结构，用来支持slot有关的操作及数据迁移指令。

Codis 使用 Go 语言开发，它是一个代理中间件，它和 Redis 一样也使用 Redis 协议 对外提供服务，当客户端向 Codis 发送指令时，Codis 负责将指令转发到后面的 Redis 实例 来执行，并将返回结果再转回给客户端。

Codis 上挂接的所有 Redis 实例构成一个 Redis 集群，当集群空间不足时，可以通过动 态增加 Redis 实例来实现扩容需求。

因为 Codis 是无状态的，它只是一个转发代理中间件，这意味着我们可以启动多个 Codis 实例，供客户端使用，每个 Codis 节点都是对等的。因为单个 Codis 代理能支撑的 QPS 比较有限，通过启动多个 Codis 代理可以显著增加整体的 QPS 需求，还能起到容灾功能，挂掉一个 Codis 代理没关系，还有很多 Codis 代理可以继续服务。

## Codis 分片原理
Codis要负责将特定的 key 转发到特定的 Redis 实例

Codis采用Pre-sharding的技术来实现数据分片，将所有的key默认分为1024个slot（0-1023)。Codis在接收到命令时，先对key进行crc32运算，然后再对1024取余，得到的结果就是对应的slot。

每个槽位都会唯一映射到后面的多个 Redis 实例之一，Codis 会在内存维护槽位和Redis 实例的映射关系。槽位数量默认是 1024，它是可以配置的，如果集群节点比较多，建议将这个数值配置大一些，比如 2048、4096。

## 不同的 Codis 实例之间槽位关系如何同步?
如果 Codis 的槽位映射关系只存储在内存里，那么不同的 Codis 实例之间的槽位关系就无法得到同步。所以 Codis 还需要一个分布式配置存储数据库专门用来持久化槽位关系。 Codis 开始使用 ZooKeeper，后来连 etcd 也一块支持了。

![image](https://user-images.githubusercontent.com/34932312/71152728-2f18ec00-2272-11ea-9956-cbbf401b0b40.png)

Codis 将槽位关系存储在 zk 中，并且提供了一个 Dashboard 可以用来观察和修改槽位 关系，当槽位关系变化时，Codis Proxy 会监听到变化并重新同步槽位关系，从而实现多个 Codis Proxy 之间共享相同的槽位关系配置。

## 扩容
刚开始 Codis 后端只有一个 Redis 实例，1024 个槽位全部指向同一个 Redis。然后一个 Redis 实例内存不够了，所以又加了一个 Redis 实例。这时候需要对槽位关系进行调整，将一半的槽位划分到新的节点。这意味着需要对这一半的槽位对应的所有 key 进行迁移，迁移到新的 Redis 实例。

Codis 对 Redis 进行了改造，增加了 SLOTSSCAN 指令，可以遍历指定 slot 下所有的 key。Codis 通过 SLOTSSCAN 扫描出待迁移槽位的所有的 key，然后挨个迁移每个 key 到新的 Redis 节点。

## Codis 的代价
Codis 给 Redis 带来了扩容的同时，也损失了其它一些特性。因为 Codis 中所有的 key 分散在不同的 Redis 实例中，所以事务就不能再支持了，事务只能在单个 Redis 实例中完成。

同样为了支持扩容，单个 key 对应的 value 不宜过大，因为集群的迁移的最小单位是 key，对于一个 hash 结构，它会一次性使用 hgetall 拉取所有的内容，然后使用 hmset 放置到另一个节点。如果 hash 内部的 kv 太多，可能会带来迁移卡顿。官方建议单个集合结构的总字节容量不要超过1M。如果我们要放置社交关系数据，例如粉丝列表这种，就需要注意了，可以考虑分桶存储，在业务上作折中。

Codis 因为增加了 Proxy 作为中转层，所有在网络开销上要比单个 Redis 大，毕竟数据包多走了一个网络节点，整体在性能上要比单个 Redis 的性能有所下降。但是这部分性能损耗不是太明显，可以通过增加 Proxy 的数量来弥补性能上的不足。

Codis 的集群配置中心使用 zk 来实现，意味着在部署上增加了 zk 运维的代价，大部分互联网企业内部都有 zk 集群，可以使用现有的 zk 集群使用即可。

## Codis 的优点
Codis 在设计上相比 Redis Cluster 官方集群方案要简单很多，因为它将分布式的问题交给了第三方 zk/etcd 去负责，自己就省去了复杂的分布式一致性代码的编写维护工作。而 Redis Cluster 的内部实现非常复杂，它为了实现`去中心化`，混合使用了复杂的 `Raft` 和 `Gossip` 协议，还有大量的需要调优的配置参数，当集群出现故障时，维护人员往往不知道从何处着手。

## MGET 指令的操作过程
![image](https://user-images.githubusercontent.com/34932312/71334468-583ec280-2579-11ea-9504-0db6f5a0f11e.png)

mget 指令用于批量获取多个 key 的值，这些 key 可能会分布在多个 Redis 实例中。 Codis 的策略是将 key 按照所分配的实例打散分组，然后依次对每个实例调用 mget 方法，最后将结果汇总为一个，再返回给客户端。


