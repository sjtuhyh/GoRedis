<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->
**Table of Contents**  *generated with [DocToc](https://github.com/thlorenz/doctoc)*

- [Redis5.0 Stream](#redis50-stream)
  - [消息ID](#%E6%B6%88%E6%81%AFid)
  - [消息内容](#%E6%B6%88%E6%81%AF%E5%86%85%E5%AE%B9)
  - [增删改查](#%E5%A2%9E%E5%88%A0%E6%94%B9%E6%9F%A5)
    - [xadd](#xadd)
    - [XDEL](#xdel)
    - [xrange](#xrange)
    - [xlen](#xlen)
    - [del](#del)
    - [示例](#%E7%A4%BA%E4%BE%8B)
  - [独立消费](#%E7%8B%AC%E7%AB%8B%E6%B6%88%E8%B4%B9)
    - [xread](#xread)
    - [独立消费](#%E7%8B%AC%E7%AB%8B%E6%B6%88%E8%B4%B9-1)
  - [创建消费组](#%E5%88%9B%E5%BB%BA%E6%B6%88%E8%B4%B9%E7%BB%84)
    - [xgroup](#xgroup)
    - [xinfo](#xinfo)
    - [示例](#%E7%A4%BA%E4%BE%8B-1)
  - [消费](#%E6%B6%88%E8%B4%B9)
    - [xreadgroup](#xreadgroup)
    - [示例](#%E7%A4%BA%E4%BE%8B-2)
  - [消息如果忘记 ACK 会怎样?](#%E6%B6%88%E6%81%AF%E5%A6%82%E6%9E%9C%E5%BF%98%E8%AE%B0-ack-%E4%BC%9A%E6%80%8E%E6%A0%B7)
  - [PEL如何避免消息丢失](#pel%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E6%B6%88%E6%81%AF%E4%B8%A2%E5%A4%B1)
  - [Stream的高可用](#stream%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8)
  - [分区Partition](#%E5%88%86%E5%8C%BApartition)
  - [小结](#%E5%B0%8F%E7%BB%93)

<!-- END doctoc generated TOC please keep comment here to allow auto update -->

# Redis5.0 Stream
Redis5.0最大的新特性就是多出了一个数据结构Stream,它是一个新的强大的支持`多播的可持久化`的消息队列

![image](https://user-images.githubusercontent.com/34932312/70028251-215f3780-15df-11ea-8491-ab1f5adc2f64.png)

Redis Stream的结构如图所示, 它有一个`消息链表`, 将所有加入的消息都串起来, 每个消息都有一个`唯一的ID和对应的内容`。

每个Stream都有唯一的名称, 它就是Redis的key, 在我们首次使用`xadd`指令追加消息时自动创建。

每个Stream都可以挂多个消费组, 每个消费组会有个游标`last_delivered_id`在 Stream数组之上往前移动, 表示当前消费组已经消费到哪条消息了。`每个消费组都有一个Stream内唯一的名称`, 消费组不会自动创建, 
它需要单独的指令`xgroup create`进行创建, 需要指定从Stream的某个消息ID开始消费, 这个ID用来初始化`last_delivered_id`变量。

每个`消费组(Consumer Group)`的状态都是独立的，相互不受影响。也就是说`同一份Stream内部的消息会被每个消费组都消费到`。

同一个消费组(Consumer Group)可以`挂接多个消费者 (Consumer)`, 这些消费者之间是竞争关系, 任意一个消费者读取了消息都会使游标last_delivered_id往前移动。`每个消费者有一个组内唯一名称`。

消费者(Consumer)内部会有个状态变量`pending_ids`, 它记录了当前已经被客户端读取的消息，但是还没有ack。如果客户端没有ack，这个变量里面的消息ID会越来越多，一旦某个消息被ack，它就开始减少。

这个pending_ids变量在Redis官方被称之为`PEL`，也就是`Pending Entries List`, 这是一个很核心的数据结构，它用来确保客户端至少消费了消息一次，而不会在网络传输的中途丢失了没处理。

## 消息ID
消息ID的形式是`timestampInMillis-sequence`

例如1527846880572-5，它表示当前的消息在毫秒时间戳1527846880572时产生, 并且是该毫秒内产生的第5条消息。

消息ID可以由服务器自动生成，也可以由客户端自己指定，但是形式必须是整数-整数，而且必须是后面加入的消息的ID要大于前面的消息ID。

## 消息内容
消息内容就是键值对，形如hash结构的键值对

## 增删改查
### xadd
时间复杂度：O(1)

向指定的stream添加元素。如果key不存在，就创建一个新的stream。

entry由一系列field-value对组成，存储顺序由用户添加顺序决定。XADD命令是唯一一个向stream中添加数据的命令。删除数据的命令则有XDEL和XTRIM。

在stream中，entry ID是唯一标识。XADD命令中ID参数是*时，会自动生成唯一ID。然而在生产环境中并不常用，通常需要我们指定一种格式较好的唯一ID。

默认的ID生成策略是：“Unix毫秒时间戳-同一毫秒值内的序列号”。

当用户显式指定ID时，最小值是0-1，且ID必须是递增的。

用户可以使用MAXLEN指定stream的最大元素数量

### XDEL
时间复杂度：O(1)

删除stream中的entry并返回删除的数量。

这里的删除仅仅是设置了标志位，不影响消息总长度

### xrange
时间复杂度：O(N)，N是返回的元素数量

用法：XRANGE key start end [COUNT count]

该命令用于返回stream中指定ID范围的数据，可以使用-和+表示最小和最大ID。ID也可以指定为不完全ID，即只指定Unix时间戳，就可以获取指定时间范围内的数据。

### xlen 
时间复杂度：O(1)

返回stream中的entry数量。如果key不存在，则返回0。对于长度为0的stream，Redis不会删除，因为可能存在关联的消费者组。

### del
删除 Stream

### 示例
```
# * 号表示服务器自动生成 ID，后面顺序跟着一堆 key/value
127.0.0.1:6379> xadd key1 * name hy age 18
"1575365874677-0"
127.0.0.1:6379> xadd key1 * name cgz age 18
"1575365886623-0"

127.0.0.1:6379> xlen key1
(integer) 2

# -表示最小值 , + 表示最大值
127.0.0.1:6379> xrange key1 - +
1) 1) "1575365874677-0"
   2) 1) "name"
      2) "hy"
      3) "age"
      4) "18"
2) 1) "1575365886623-0"
   2) 1) "name"
      2) "cgz"
      3) "age"
      4) "18"
      
# 指定最大消息 ID 的列表      
127.0.0.1:6379> xrange key1 - 1575365874677-0
1) 1) "1575365874677-0"
   2) 1) "name"
      2) "hy"
      3) "age"
      4) "18"

127.0.0.1:6379> xdel key1 1575365874677-0
(integer) 1

# 被删除的消息没了
127.0.0.1:6379> xrange key1 - +
1) 1) "1575365886623-0"
   2) 1) "name"
      2) "cgz"
      3) "age"
      4) "18"
      
# 删除整个 Stream
127.0.0.1:6379> del key1
(integer) 1      
```

## 独立消费
### xread
时间复杂度：O(N)，N是返回的元素数量

用法：XREAD [COUNT count] [BLOCK milliseconds] STREAMS key [key …] ID [ID …]

从一个或多个stream中读取数据，仅返回ID大于调用者报告的最后接收ID的条目。

BLOCK项用于指定阻塞时长。STREAMS项必须在最后，用于指定stream和ID。

### 独立消费
我们可以在不定义消费组的情况下进行Stream消息的独立消费, 当Stream没有新消息时, 甚至可以阻塞等待。

Redis设计了一个单独的消费指令`xread`，可以将Stream 当成普通的消息队列 (list) 来使用。使用xread时，我们可以完全忽略消费组 (Consumer Group) 的存在，就好比 Stream 就是一个普通的列表 (list)。

```
# 从 Stream 头部读取两条消息
127.0.0.1:6379> xread count 2 streams key1  0-0
1) 1) "key1"
   2) 1) 1) "1575366167258-0"
         2) 1) "name"
            2) "hy"
            3) "age"
            4) "18"
      2) 1) "1575366171199-0"
         2) 1) "name"
            2) "cgz"
            3) "age"
            4) "18"

# 从 Stream 尾部读取一条消息，毫无疑问，这里不会返回任何消息            
127.0.0.1:6379> xread count 1 streams key1 $
(nil)

# 从尾部阻塞等待新消息到来，下面的指令会堵住，直到新消息到来
127.0.0.1:6379> xread count 1 block 0 streams key1 $

# 我们从新打开一个窗口，在这个窗口往 Stream 里塞消息
127.0.0.1:6379> xadd key1 * name 111 age 12
"1575366612200-0"

# 再切换到前面的窗口，我们可以看到阻塞解除了，返回了新的消息内容 
# 而且还显示了一个等待时间，这里我们等待了 93s
127.0.0.1:6379> xread count 1 block 0 streams key1 $
1) 1) "key1"
   2) 1) 1) "1575366612200-0"
         2) 1) "name"
            2) "111"
            3) "age"
            4) "12"
(27.02s)
```

客户端如果想要使用 xread 进行顺序消费，一定要记住当前消费到哪里了，也就是返回的消息 ID。下次继续调用 xread 时，将上次返回的最后一个消息 ID 作为参数传递进去，就可以继续消费后续的消息。

block 0 表示永远阻塞，直到消息到来，block 1000 表示阻塞 1s，如果 1s 内没有任何消息到来，就返回 nil。
```
127.0.0.1:6379> xread block 1000 count 1 streams codehole $
(nil)
(1.14s)
```

## 创建消费组
![image](https://user-images.githubusercontent.com/34932312/70040692-eb2db200-15f6-11ea-9d7b-fcb155f3dd05.png)

### xgroup
时间复杂度：每个子命令是O(1)

该命令用于管理stream相关的消费者组。使用XGROUP命令你可以：
- 创建与一个stream相关联的消费者组
- 销毁一个消费者组
- 从消费者组中删除指定的消费者
- 设置消费者组的last delivered ID

创建新的消费者组的命令是：
```
1XGROUP CREATE mystream consumer-group-name $
```
最后一个参数是stream中已传递的最后一个ID，使用$表示这个消费者组只能获取到新的元素。

### xinfo
时间复杂度：O(N)，N是CONSUMERS和GROUPS返回的item数量

用法：XINFO [CONSUMERS key groupname] [GROUPS key][STREAM key] [HELP]

这个命令用于返回stream和相关消费者组的不同信息。它有三种形式。

```
XINFO STREAM
这个命令返回stream的通用信息

XINFO GROUPS
这个命令用于获得stream相关的消费者组的信息

XINFO CONSUMERS
这个命令返回指定消费者组的消费者列表
```

### 示例
```
# 表示从头开始消费
127.0.0.1:6379> xgroup create key1 hy1 0-0
OK

# $ 表示从尾部开始消费，只接受新消息，当前 Stream 消息会全部忽略
127.0.0.1:6379> xgroup create key1 hy2 $
OK

# 获取 Stream 信息
127.0.0.1:6379> xinfo stream key1
 1) "length"
 2) (integer) 4   # 共 4 个消息
 3) "radix-tree-keys"
 4) (integer) 1
 5) "radix-tree-nodes"
 6) (integer) 2
 7) "groups"
 8) (integer) 2   # 两个消费组
 9) "last-generated-id"
10) "1575366612200-0"
11) "first-entry"   # 第一个消息
12) 1) "1575366167258-0"
    2) 1) "name"
       2) "hy"
       3) "age"
       4) "18"
13) "last-entry"   # 最后一个消息
14) 1) "1575366612200-0"
    2) 1) "name"
       2) "111"
       3) "age"
       4) "12"

# 获取 Stream 的消费组信息
127.0.0.1:6379> xinfo groups key1
1) 1) "name"
   2) "hy1"
   3) "consumers"
   4) (integer) 0  # 该消费组还没有消费者
   5) "pending"
   6) (integer) 0  # 该消费组没有正在处理的消息
   7) "last-delivered-id"
   8) "0-0"
2) 1) "name"
   2) "hy2"
   3) "consumers"
   4) (integer) 0
   5) "pending"
   6) (integer) 0
   7) "last-delivered-id"
   8) "1575366612200-0"       
```

## 消费
Stream提供了`xreadgroup`指令进行消费组的组内消费, 需要提供消费组名称、消费者名称和起始消息ID。

它同 xread 一样，也可以阻塞等待新消息。`读到新消息后，对应的消息 ID 就会进入消费者的 PEL(正在处理的消息) 结构里`, 客户端处理完毕后使用xack指令通知服务器, 本条消息已经处理完毕，该消息 ID 就会从 PEL 中移除。

### xreadgroup
时间复杂度：O(log(N)+M) ，N是返回的元素数量，M是一个常量。

用法：XREADGROUPGROUP group consumer [COUNT count] [BLOCK milliseconds] STREAMS key [key …] ID [ID …]

XREADGROUP是XREAD的特殊版本，支持消费者组。

### 示例
```
# > 号表示从当前消费组的 last_delivered_id 后面开始读
# 每当消费者读取一条消息，last_delivered_id 变量就会前进
127.0.0.1:6379> xreadgroup GROUP hy1 c1 count 1 streams key1 >
1) 1) "key1"
   2) 1) 1) "1575366167258-0"
         2) 1) "name"
            2) "hy"
            3) "age"
            4) "18"

127.0.0.1:6379> xreadgroup GROUP hy1 c1 count 1 streams key1 >
1) 1) "key1"
   2) 1) 1) "1575366171199-0"
         2) 1) "name"
            2) "cgz"
            3) "age"
            4) "18"
            
127.0.0.1:6379> xreadgroup GROUP hy1 c1 count 2 streams key1 >
1) 1) "key1"
   2) 1) 1) "1575366191697-0"
         2) 1) "name"
            2) "hyh"
            3) "age"
            4) "10"
      2) 1) "1575366612200-0"
         2) 1) "name"
            2) "111"
            3) "age"
            4) "12"

# 再继续读取，就没有新消息了
127.0.0.1:6379> xreadgroup GROUP hy1 c1 count 1 streams key1 >
(nil)

# 观察消费组信息
127.0.0.1:6379> xinfo groups key1
1) 1) "name"
   2) "hy1"
   3) "consumers"
   4) (integer) 1   # 一个消费者
   5) "pending"
   6) (integer) 4  # 共4条正在处理的信息还有没有ack
   7) "last-delivered-id"
   8) "1575366612200-0"
2) 1) "name"
   2) "hy2"
   3) "consumers"
   4) (integer) 0  # 消费组hy2没有任何变化，因为前面我们一直在操纵hy1
   5) "pending"
   6) (integer) 0
   7) "last-delivered-id"
   8) "1575366612200-0"
   
# 接下来我们 ack 一条消息
127.0.0.1:6379> xack key1 hy1 1575366167258-0
(integer) 1

127.0.0.1:6379> xinfo consumers key1 hy1
1) 1) "name"
   2) "c1"
   3) "pending"
   4) (integer) 3   # 变成了3条
   5) "idle"
   6) (integer) 280073

```

## 消息如果忘记 ACK 会怎样?
Stream 在每个消费者结构中保存了正在处理中的`消息ID列表PEL`

如果消费者收到了消息处理完了但是没有回复 ack，就会导致 PEL 列表不断增长，如果有很多消费组的话，那么这个 PEL 占用的内存就会放大。

![image](https://user-images.githubusercontent.com/34932312/70124098-fcd29080-16ae-11ea-8e2b-e9b2e995100d.png)

## PEL如何避免消息丢失
在客户端消费者读取Stream消息时，Redis服务器将消息回复给客户端的过程中，客户端突然断开了连接，消息就丢失了。但是 PEL 里已经保存了发出去的消息ID。待客户端重新连上之后，可以再次收到PEL中的消息ID列表。不过此时 xreadgroup 的起始消息ID 不能为参数>，而必须是任意有效的消息 ID，一般将参数设为 0-0，表示读取所有的PEL 消息以及自 last_delivered_id 之后的新消息。

## Stream的高可用
Stream 的高可用是建立主从复制基础上的，它和其它数据结构的复制机制没有区别，也就是说在 Sentinel 和 Cluster 集群环境下 Stream 是可以支持高可用的。不过鉴于 Redis 的指令复制是异步的，在 failover 发生时，Redis 可能会丢失极小部分数据，这点 Redis 的其它数据结构也是一样的。

Redis 的指令复制是异步的：主节点不但负责数据读写，还负责把写命令同步给从节点。写命令的发送过程是异步完成，也就是说主节点自身处理完写命令后直接返回给客户端，并不等待从节点复制完成。

## 分区Partition
Redis的服务器没有原生支持分区能力，如果想要使用分区，那就需要分配多个Stream，然后在客户端使用一定的策略来生产消息到不同的 Stream。

你也许会认为 Kafka 要先进很多，它是原生支持 Partition 的。关于这一点，我并不认同。记得 Kafka 的客户端也存在 HashStrategy 么，因为它也是通过客户端的 hash 算法来将不同的消息塞入不同分区的。

另外,Kafka 还支持动态增加分区数量的能力，但是这种调整能力也是很蹩脚的，它不会把之前已经存在的内容进行 rehash，不会重新分区历史数据。这种简单的动态调整的能力 Redis Stream 通过增加新的 Stream 就可以做到。

## 小结
Stream 的消费模型借鉴了 Kafka 的消费分组的概念，它弥补了 Redis Pub/Sub 不能持久化消息的缺陷。但是它又不同于 kafka，Kafka 的消息可以分partition，而 Stream 不行。 如果非要分 parition 的话，得在客户端做，提供不同的 Stream 名称，对消息进行 hash 取模来选择往哪个 Stream 里塞。