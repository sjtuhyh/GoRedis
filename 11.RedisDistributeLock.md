# Redis 分布式锁
分布式应用进行逻辑处理时经常会遇到并发问题。

比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完了再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存状态这两个操作不是原子的。

所谓原子操作是指不会被线程调度机制打断的操作;这种操作一旦开始，就一直运行到结束，中间不会有任何 context switch 线程切换。

![image](https://user-images.githubusercontent.com/34932312/71453245-3a659d80-27c5-11ea-9149-0ca41173bf3e.png)

这个时候就要使用到分布式锁来限制程序的并发执行。

## 分布式锁
分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。占坑一般是使用`setnx(set if not exists)`指令，`只允许被一个客户端占坑`。先来先占，用完了，再调用 del 指令释放茅坑。
```
> setnx lock:codehole true 
OK
... do something critical ... 
> del lock:codehole (integer) 
1
```
但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样就会`陷入死锁`，锁永远得不到释放。于是我们在拿到锁之后，再给锁加上一个过期时间，比如 5s，这样即使中间出现异常也可以保证 5 秒之后锁会自动释放。
```
> setnx lock:codehole true 
OK
> expire lock:codehole 5 
... do something critical ... 
> del lock:codehole 
(integer) 1
```
以上逻辑还有问题。如果在 setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会导致 expire 得不到执行，也会`造成死锁`。

这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令。

如果这两条指令可以一起执行就不会出现问题。也许你会想到用 Redis 事务来解决。但是这里不行，因为 expire 是依赖于 setnx 的执行结果的，`如果 setnx 没抢到锁，expire 是不应该执行的`。事务里没有 if- else 分支逻辑，事务的特点是`一口气执行`，要么全部执行要么一个都不执行。

为了解决这个疑难，Redis 开源社区涌现了一堆分布式锁的library，专门用来解决这个问题。实现方法极为复杂，小白用户一般要费很大的精力才可以搞懂。如果你需要使用分布式锁，意味着你不能仅仅使用 Jedis 或者 redis-py 就行了，还得引入分布式锁的 library。

为了治理这个乱象，Redis 2.8 版本中作者加入了 set 指令的扩展参数，使得`setnx 和 expire 指令可以一起执行`，彻底解决了分布式锁的乱象。从此以后所有的第三方分布式锁 library 可以休息了。 
```
> set lock:codehole true ex 5 nx 
OK 
... do something critical ... 
> del lock:codehole 
上面这个指令就是 setnx 和 expire 组合在一起的原子指令，它就是分布式锁的奥义所在。
```

## 超时问题
Redis 的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程逻辑执行完之间拿到了锁。

为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了，数据出现的小波错乱可能需要人工介入解决。

## Lua 脚本可以保证连续多个指令的原子性执行
```
const (
	// conn不同时, 以connectAt较大值为准
	RedisScriptRtstreamSet = `-- KEYS rtstream:streamID ARGUMENTS streamStr conn connectAt
local result = ""

local oldStr = redis.call("GET", KEYS[1])
if oldStr ~= false then
	if oldStr ~= "" then
		local oldData = cjson.decode(oldStr)
		if oldData["status"] == "connected" and oldData["conn"] ~= ARGV[2] then
			if tonumber(oldData["connectAt"]) >= tonumber(ARGV[3]) then
				result = "stream is exist"
				return result
			end
		end
	end
end

if result == "" then
	redis.call("SET", KEYS[1], ARGV[1])
end

return result
`
	// conn匹配时进行删除
	RedisScriptRtstreamRemove = `-- KEYS rtstream:streamID ARGUMENTS conn
local result = ""

local oldStr = redis.call("GET", KEYS[1])
if oldStr == false then
	return
end

if oldStr ~= "" then
	local oldData = cjson.decode(oldStr)
	if oldData["status"] == "connected" and oldData["conn"] ~= ARGV[1] then
		result = "conn not match"
		return result
	end
end

if result == "" then
	redis.call("DEL", KEYS[1])
end

return result
`
)

pipeline.Eval(RedisScriptRtstreamSet, []string{formatRtstreamKey(stream.ID)}, string(streamStr), stream.Conn, stream.ConnectAt)
pipeline.Eval(RedisScriptRtstreamRemove, []string{formatRtstreamKey(stream.ID)}, stream.Conn)
```

## 可重入锁

## RedLock

第一个客户端在主节点中申请成功了一把锁，但是这把锁还没有来得及同步到从节点，主节点突然挂掉了。然后从节点变成了主节点，这个新的节点内部没有这个锁，所以 另一个客户端过来请求加锁时，立即就批准了。这样就会导致系统中同样一把锁被两个客户端同时持有，不安全性由此产生。

不过这种不安全也仅仅是在主从发生 failover 的情况下才会产生，而且持续时间极短， 业务系统多数情况下可以容忍。

https://www.cnblogs.com/rgcLOVEyaya/p/RGC_LOVE_YAYA_1003days.html

